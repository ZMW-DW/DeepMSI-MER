# MELD
MELD_train_video_path = '../data/MELD/train/video'
MELD_train_text_path = '../data/MELD/train/text'
MELD_train_audio_path = '../data/MELD/train/audio'

MELD_valid_video_path = '../data/MELD/valid/video'
MELD_valid_text_path = '../data/MELD/valid/text'
MELD_valid_audio_path = '../data/MELD/valid/audio'

MELD_test_video_path = '../data/MELD/test/video'
MELD_test_text_path = '../data/MELD/test/text'
MELD_test_audio_path = '../data/MELD/test/audio'

MELD_train = '../data/MELD/train.csv'
MELD_valid = '../data/MELD/valid.csv'
MELD_test = '../data/MELD/test.csv'


# IEMOCAP
IEMOCAP_train_video_path = '../data/IEMOCAP/train/video'
IEMOCAP_train_text_path = '../data/IEMOCAP/train/text'
IEMOCAP_train_audio_path = '../data/IEMOCAP/train/audio'

IEMOCAP_valid_video_path = '../data/IEMOCAP/valid/video'
IEMOCAP_valid_text_path = '../data/IEMOCAP/valid/text'
IEMOCAP_valid_audio_path = '../data/IEMOCAP/valid/audio'

IEMOCAP_test_video_path = '../data/IEMOCAP/test/video'
IEMOCAP_test_text_path = '../data/IEMOCAP/test/text'
IEMOCAP_test_audio_path = '../data/IEMOCAP/test/audio'

IEMOCAP_train = '../data/IEMOCAP/train.txt'
IEMOCAP_valid = '../data/IEMOCAP/valid.txt'
IEMOCAP_test = '../data/IEMOCAP/test.txt'


# Training parameters
batch_size = 16
num_workers = 4
# lr = 1e-5
lr = 1e-4 # MELD
weight_decay = 1e-5
patience = 4
factor = 0.5
epochs = 30

# Image encoder model configuration
image_input = 768
image_embedding = 1024

# Text encoder model configuration
text_embedding = 1024

# Audio encoder model configuration
audio_embedding = 768



"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""




"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
                                        初始设置： dropout_rate = 0.2 或 0.3。
                                        调节策略： 观察验证集的损失和准确率，适时调整 dropout 值来防止过拟合。
"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
# Projection head configuration (used for both image and text encoders)
num_projection_layers = 2
Projection_dropout = 0.2
projection_dim = 256


# cls操作
tCLS_dropout = 0.3
tCLS_layers = 2
processor_dropout = 0.3
processor_hidden_dims = [512]

"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
                较小的隐藏维度（保守设置）：[512, 256, 128] 或 [512, 256]
                更复杂的网络（如果数据集较大或更复杂）：[512, 384, 256, 128] 或 [512, 256, 128, 64]
                Dropout：通常设置在 0.2 - 0.4 之间。对于情感分析任务，增加 dropout 有助于提高模型的泛化能力，防止过拟合，尤其是在数据集较小或模型较复杂时。
                交叉熵由于分类的比例不相同 所以需要设置class_weights
"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
classifier_hidden_dims = [512, 256, 128]
classifier_dropout = 0.3
classifier_num_classes = 6                      ##### IEMOCAP
# classifier_num_classes = 7                    ##### MELD


"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
            通道数递减：推荐配置 [1024, 512, 512] 或 [1024, 768, 512]: [1024, 1024, 512]
            恒定通道数：例如 num_channels = [1024, 1024, 1024]:
                    即保持较高的固定维度。这有助于保持通道内信息的一致性，让模型有更强的时序建模能力，适合需要丰富情感细节的任务。
                    
                    注意改变最后一个维度 还需要对后面进行修改 映射需要知道视频特征维度
                    TNC_dropout = 0.3 不大行
"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
# num_channels = [768, 768, 768]
num_channels = [1024, 1024, 1024]
TNC_dropout = 0.3


"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
                                        为找到最优超参数组合，可以通过实验验证以下设置：

                                        固定 alpha，调整 similarity_threshold：

                                        固定 alpha = 0.9，分别测试 similarity_threshold = 0.5, 0.6, 0.7, 0.8，观察筛选后的性能变化。
                                        指标包括：筛选出的特征数量占比、模型训练损失、验证集性能。
                                        固定 similarity_threshold，调整 alpha：

                                        固定 similarity_threshold = 0.6，分别测试 alpha = 0.8, 0.85, 0.9, 0.95。
                                        观察模型在验证集上的性能是否随 alpha 提升而改善。
                                        网格搜索：

                                        结合上述两者，选择一个小范围网格进行组合实验。例如：

                                        alpha = [0.85, 0.9, 0.95]
                                        similarity_threshold = [0.5, 0.6, 0.7]
                                        共测试 

                                        3×3=9 种组合，选择验证集性能最优的配置。

"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
similarity_threshold=0.6
VSC_alpha=0.9


"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
                                           ------   temperature   ------
1、较高的温度（如 τ > 1）：使得相似度分布更加平滑，减少了负样本对的影响。适合于不容易区分正负样本的任务，或当数据较复杂时。
2、较低的温度（如 τ < 1）：使得相似度分布更加尖锐，强调最相似的样本对，减少了正样本和负样本之间的混淆。适合于样本区分度较高的任务，可以加速训练过程，但可能导致训练的不稳定。
3、标准值：通常，温度设置在 0.1 ~ 0.5 之间常见。τ = 0.1 会使得对比学习变得更加严格，而 τ = 0.5 或稍高的温度则可能会让模型有更多的容错空间。

实际应用建议：
经验选择：如果您不确定温度的选择，建议从 τ = 0.2 ~ 0.5 开始测试，这个范围通常能得到较好的效果。
动态调整：某些任务中，您可以尝试逐步调整温度。例如，在训练初期使用较大的温度（例如 τ = 0.5），以便模型更好地学习数据分布，之后再逐渐减小温度（如 τ = 0.1），以促进更精细的区分。
"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
temperature = 0.5

"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
            alpha 和 beta 的值决定了对比学习损失（contrastive loss）和分类损失（cross-entropy loss）在模型训练中的相对重要性
            1、初始选择：
                    alpha = 0.5，beta = 1.0 是一个常见的初始设置。即，分类损失的重要性稍大于对比损失。
                    这通常适用于基于对比学习和分类目标的联合训练，因为交叉熵损失对最终的三分类结果有更直接的优化作用，而对比损失在帮助模型更好地聚合同类特征。
            2、任务驱动的调整
                    如果你的模型在分类任务上效果不好（例如准确率低），可以增大 beta 的值（例如设为 1.5 或 2.0），以增加交叉熵的权重，让模型更专注于分类任务。
                    如果你发现视频和文本特征之间的对比关系不够清晰，可以增大 alpha（例如设为 1.0 或更高）来加强对比损失，让模型更关注跨模态的情感一致性。
            3、调参建议
                    初始设置 alpha = 0.5 和 beta = 1.0 后，逐步调整每次仅改变一个参数：
                    将 alpha 增大到 0.8 或 1.0 测试对比学习的效果。
                    将 beta 增大到 1.5 或 2.0 测试交叉熵损失的影响。
                    可以通过在验证集上监测模型的分类准确率、特征聚类效果等指标来决定最终的 alpha 和 beta。
"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
alpha = 0.5   #对比学习
beta  = 1.0   #交叉熵


